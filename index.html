<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Muhammad Haseeb | ML Researcher</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

  <header class="main-header">
    <nav class="main-nav">
      <ul>
        <li><a href="index.html" class="active">Home</a></li>
        <li><a href="research.html">Research & Projects</a></li>
      </ul>
    </nav>
  </header>

  <div class="container">
    <section class="intro">
      <img src="dp.png" alt="Muhammad Haseeb" class="intro-photo">
      <div class="intro-text">
          <h1 class="intro-name">Muhammad Haseeb</h1>
          <p class="intro-subtitle">Research Assistant | Machine Learning Engineer</p>
          <p class="intro-keywords">Model Compression | Domain Generalization | Mechanistic Interpretability</p>
      </div>
      
      <!-- Decorative elements - no content, pure aesthetics -->
      <div class="intro-decoration intro-decoration-1"></div>
      <div class="intro-decoration intro-decoration-2"></div>
    </section>

    <div class="main-layout">
      <main class="main-column">
        <section id="about">
          <p>
            Hi, I'm Haseeb, a final-year CS undergraduate at LUMS (exp. 2026) working in domains of efficient, generalizable and interpretable ML. My research focuses on developing novel methods for <strong>model compression</strong> and <strong>domain generalization</strong>. A core theme of my work is using mechanistic interpretability to analyze how these techniques fundamentally alter a model's internal circuits, which helps deepen my understanding of the problem posed.
          </p>
          <p>
            I currently work as a Research Assistant at the <a href="https://city.lums.edu.pk/" target="_blank" rel="noopener noreferrer"><strong>Centre for Urban Informatics, Technology and Policy (CITY)</strong></a> at LUMS under the supervision of <a href="https://scholar.google.com/citations?user=pd9S_mcAAAAJ&hl=en" target="_blank" rel="noopener noreferrer"><strong>Dr. Muhammad Tahir</a></strong> and <a href="https://scholar.google.com/citations?user=by5tc-oAAAAJ&hl=en" target="_blank" rel="noopener noreferrer"><strong>Dr. Zubair Khalid</strong></a>. My projects here include the Backbone Contrastive Pruning <strong>(BaCP)</strong> framework to prevent representational collapse in extremely sparse networks. I am also leading a project on domain generalization where I am working to identify and remove domain specific circuits in models through the lens of Mechanistic Interpretability. I have also been associated with an external company <a href="https://10xengineers.ai/" target="_blank" rel="noopener noreferrer"><strong>10x Engineers</strong></a> for Quantization of Diffusion Models where I developed a method to train MLPs on per layer timestep stats to accurately predict quantization scale and zero-point.
          </p>
          <p>
            Previously, I contributed to research at the <a href="https://www.researchgate.net/lab/CVGL-LUMS-Murtaza-Taj" target="_blank" rel="noopener noreferrer"><strong>Computer Vision & Graphics Lab</strong></a>, where I developed <strong>KLAWQ</strong>, a GPTQ-inspired quantization method beating vanilla GPTQ by upto 30 percent in terms of perplexity. I also engineered a framework to Transformer-based model with mathematical constraints  for single-image camera calibration. I was also selected for the extremely competitive <strong>UIUC+ Summer Research Internship 2025</strong>. I worked with <a href="https://scholar.google.com/citations?user=x6OIBq4AAAAJ&hl=en" target="_blank" rel="noopener noreferrer"><strong>Dr. Darko Marinov</strong></a> on applying LLMs to automated software engineering challenges like debloating. I was also involved for a short period with <a href="https://scholar.google.com/citations?user=9gmW8MYAAAAJ&hl=en" target="_blank" rel="noopener noreferrer"><strong>Dr. Reyhaneh Jabbarvand</strong></a> on C-to-Rust code translation with LLMs.
          </p>
          <p>
            Beyond academia, my contract role as a Machine Learning Engineer at <strong>Innova Tech</strong> gave me hands-on experience in quantizing and deploying vision models on edge devices using ONNX and TensorRT. I am also an active open-source contributor to major ML libraries like timm and adapters. 
          </p>
        </section>

        <section id="highlights">
            <h2>Selected Research Highlights</h2>
            <ul class="highlights-list">
                <li>Contributed to the <a href="research.html#pub-bacp">BaCP framework</a>, engineering a multi-objective loss function to prevent representational collapse in networks at 99% sparsity.</li>
                <li>Developed a novel <a href="research.html#project-diffusion">quantization method for Diffusion Models</a> that improves performance by 55% over baselines by predicting parameters from the signal-to-noise ratio.</li>
                <li>Designed a <a href="research.html#project-dg">Domain Generalization framework</a> using learnable visual queries that yielded a 3% accuracy gain on the PACS benchmark.</li>
                <li>Investigated the mechanistic causes of performance degradation in Federated Learning, proposing a new "circuit collapse" hypothesis in <a href="research.html#project-fedmi">FedMI</a>.</li>
            </ul>
        </section>
      </main>

      <aside class="sidebar-column">
        <div class="news-box">
            <h3>Experience & Teaching</h3>
            <ul>
                <li>
                    <strong>Machine Learning Engineer (Contract)</strong> at Innova Tech<br>
                    Owned optimization pipeline for on-device object detection. Led ONNX/TensorRT quantization, reducing memory by 40% with real-time inference. Automated data annotation pipeline, improving accuracy by 4%.
                </li>
                <li>
                    <strong>Teaching Assistant, CS436: Computer Vision</strong> at LUMS<br>
                    Designed assignments on PyTorch transfer learning and C++/OpenCV pipelines. Mentored 40 groups (80+ students) on SfM-based virtual tour projects.
                </li>
            </ul>
        </div>
        <div class="news-box">
            <h3>Open Source Contributions</h3>
            <ul>
                <li>
                    <strong>Contributor, pytorch-image-models (timm)</strong><br>
                    Implemented F1, precision, recall metrics for distributed training using torch.distributed.
                </li>
                <li>
                    <strong>Contributor, adapters (PEFT Library)</strong><br>
                    Added GQA support for Llama-2/Mistral PEFT. Fixed tensor shape mismatch bug, enabling PEFT for modern LLMs.
                </li>
            </ul>
        </div>
      </aside>
    </div>

    <section id="interests" class="highlight-section">
        <h2>Research Interests</h2>
        <ul class="interests-list">
            <li>Model Compression (Pruning & Quantization)</li>
            <li>Domain Generalization & OOD Robustness</li>
            <li>Mechanistic Interpretability</li>
            <li>AI on Edge Devices</li>
            <li>Camera Calibration & 3d Reconstruction</li>
        </ul>
    </section>

    <footer class="page-footer">
        <p>&copy; 2026 Muhammad Haseeb. Last Updated: January 2026.</p>
    </footer>

  </div>
</body>
</html>