<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Muhammad Haseeb | ML Researcher</title>
  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=Source+Serif+Pro:wght@600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="wrapper">
    <aside class="sidebar">
      <img src="gdp.png" alt="Muhammad Haseeb" class="profile-photo">
      <h1 class="sidebar-name">Muhammad Haseeb</h1>
      <div class="sidebar-title">Machine Learning Engineer | CS Undergrad</div>
      <div class="sidebar-affiliation">Lahore University of Management Sciences</div>

      <ul class="sidebar-links">
        <li><a href="mailto:haseeb099m@gmail.com"><i class="icon fas fa-envelope"></i> Email</a></li>
        <li><a href="https://github.com/ha405" target="_blank"><i class="icon fab fa-github"></i> GitHub</a></li>
        <li><a href="https://linkedin.com/in/muhammad-haseeb" target="_blank"><i class="icon fab fa-linkedin"></i> LinkedIn</a></li>
        <li><a href="cv.pdf" class="cv-button"><i class="icon fas fa-file-pdf"></i> Download CV</a></li>
      </ul>
    </aside>

    <main class="content">
      <section id="about">
        <h2>About Me</h2>
        <p>
          I am a final-year Computer Science undergraduate at LUMS (exp. 2026). My research is focused on developing practical and efficient large-scale neural networks. I develop novel methods for <strong>model compression</strong> and <strong>domain generalization</strong>. A core theme of my research is using <strong>mechanistic interpretability</strong> to analyze how these techniques fundamentally alter a model's internal circuits, which deepens my understanding of the problem posed.
        </p>
      </section>

      <section id="timeline">
        <h2>Timeline</h2>
        <ul class="timeline">
          <li>
            <span class="timeline-date">Jan 2025 - Present</span>
            <span class="timeline-event">Leading projects in Interpretability, Domain Generalization, and Compression at CITY, LUMS.</span>
          </li>
          <li>
            <span class="timeline-date">Sep 2025 - Dec 2025</span>
            <span class="timeline-event">Served as Teaching Assistant for CS436: Computer Vision, mentoring 80 students in Programming Assignment and Course Project.</span>
          </li>
          <li>
            <span class="timeline-date">May 2025 - Aug 2025</span>
            <span class="timeline-event">Completed a research internship at the University of Illinois Urbana-Champaign (UIUC).</span>
          </li>
          <li>
            <span class="timeline-date">Jan 2025 - Aug 2025</span>
            <span class="timeline-event">Developed a GPTQ-inspired quantization and ViT-based camera calibration method at the Computer Vision & Graphics Lab, LUMS.</span>
          </li>
        </ul>
      </section>

      <section id="interests">
        <h2>Research Interests</h2>
        <ul class="interests-list">
            <li><strong>Model Compression:</strong> Researching pruning and quantization methods to reduce the computational and memory footprint of neural networks while preserving performance.</li>
            <li><strong>Domain Generalization:</strong> Developing methods that adapt models to distribution shifts by identifying and preserving sparse, domain-invariant subnetworks.</li>
            <li><strong>Mechanistic Interpretability:</strong> Analyzing internal circuit evolution to understand phenomena like representational collapse in federated learning.</li>
        </ul>
      </section>

      <section id="publications">
        <h2>Publications</h2>
        <div class="item">
          <details>
            <summary>
              <span class="item-title">BaCP: Backbone Contrastive Pruning for Preserving Representations in Extremely Sparse Neural Networks</span>
              <div class="item-meta">M. H. Khawaja, <strong>M. Haseeb</strong>, M. F. Shoaib, M. Tahir. <em>(Submitted to AAAI 2025)</em></div>
            </summary>
            <div class="item-details-content">
              <p>As a contributor to this work, I tackled the problem of representational collapse in highly sparse networks. We designed and implemented the multi-objective loss function that aligns sparse embeddings against three critical references (pretrained, fine-tuned, and historical). We tested our framework across CNNs, Vision Transformers, and Language Models to verify that our method preserves accuracy at extreme sparsity.</p>
            </div>
          </details>
        </div>
      </section>

      <section id="projects">
        <h2>Research Projects</h2>
        <div class="item">
          <details>
            <summary>
                <span class="item-title">Domain Generalization via Visual Queries</span>
                <div class="item-meta">Role: Project Lead | CITY, LUMS</div>
            </summary>
            <div class="item-details-content">
                <p>Developed a framework using learnable visual queries to improve out-of-distribution performance. By training these queries with a group relative optimization objective, I guided the model to learn domain-invariant features. My implementation <strong>achieved a 3% accuracy gain</strong> on the PACS dataset over the ERM baseline. I am now extending this work by designing a pruning methodology to physically remove domain-specific circuits from the network.</p>
            </div>
          </details>
        </div>
        <div class="item">
          <details>
            <summary>
                <span class="item-title">KL-Aware Quantization (KLAWQ)</span>
                <div class="item-meta">Role: Project Lead | CV & Graphics Lab, LUMS</div>
            </summary>
            <div class="item-details-content">
                <p>Developed an augmented GPTQ framework that integrates knowledge distillation and supervised fine-tuning directly into the post-training quantization pipeline. My key technical innovation was combining the standard GPTQ Hessian with second-order curvature information from KL-divergence and cross-entropy objectives. This better preserves the teacher model's outputs, and my implementation <strong>achieved a 30% reduction in perplexity</strong> over the baseline GPTQ at equivalent bit-widths.</p>
            </div>
          </details>
        </div>
        <div class="item">
          <details>
            <summary>
                <span class="item-title">Single-Image Camera Calibration (SOFI-UGCL)</span>
                <div class="item-meta">Role: Contributor | CV & Graphics Lab, LUMS</div>
            </summary>
            <div class="item-details-content">
                <p>Engineered a hybrid method for camera calibration combining a Transformer front-end with geometric post-processing. I took a pretrained Multi-Scale Deformable Transformer (SOFI) to predict geometric primitives like the zenith point and horizon line. From these predictions, I <strong>developed the algorithm to derive the camera's intrinsic (K) and extrinsic (R, t) parameters</strong> while enforcing rotation matrix orthonormality, enabling recovery of the full projection matrix from a single image.</p>
            </div>
          </details>
        </div>
      </section>
      
      <section id="opensource">
        <h2>Open Source Contributions</h2>
        <div class="item">
          <details>
            <summary>
                <span class="item-title">Contributor, pytorch-image-models (timm)</span>
                <div class="item-meta">Role: Core Evaluation Metrics</div>
            </summary>
            <div class="item-details-content">
                <p>Implemented F1, precision, and recall metrics into the core evaluation loop of the popular `timm` library. My contribution specifically handles distributed training environments by correctly aggregating metrics across multiple GPUs using `torch.distributed` primitives, ensuring accuracy even with uneven batch sizes.</p>
            </div>
          </details>
        </div>
        <div class="item">
          <details>
            <summary>
                <span class="item-title">Contributor, adapters (PEFT Library)</span>
                <div class="item-meta">Role: GQA Support for Modern LLMs</div>
            </summary>
            <div class="item-details-content">
                <p>Extended the `adapters` library to support Parameter-Efficient Fine-Tuning (PEFT) for models using Group Query Attention (GQA), such as Llama-2 and Mistral. As part of this, I identified and fixed a critical tensor shape mismatch bug, unblocking PEFT for these newer, memory-efficient architectures.</p>
            </div>
          </details>
        </div>
      </section>

      <!-- Fun Fact Section -->
      <section id="fun-facts">
        <h2>Just for Fun</h2>
        <div class="fun-fact-container">
          <div id="fact-display" class="fun-fact-text">
            Click the button for a random fact about my life as a researcher!
          </div>
          <button class="fun-fact-btn" onclick="newFact()">Tell me something else</button>
        </div>
      </section>

    </main>
  </div>

  <script>
    const facts = [
      "I believe every problem can be solved with enough GPU memory... or smarter quantization.",
      "My favorite debugging tool is still a good night's sleep.",
      "I spend 90% of my time debugging tensor dimension mismatches.",
      "I'm learning Rust because C++ gave me trust issues.",
      "I once optimized a model so much it forgot what a 'cat' was. Representational collapse is real!"
    ];

    function newFact() {
      const display = document.getElementById('fact-display');
      const randomFact = facts[Math.floor(Math.random() * facts.length)];
      
      // Simple fade animation
      display.style.opacity = 0;
      setTimeout(() => {
        display.innerText = `"${randomFact}"`;
        display.style.opacity = 1;
      }, 200);
    }
  </script>

</body>
</html>