<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Muhammad Haseeb</title>
  <link rel="stylesheet" href="style.css"/>
</head>
<body>
  <div class="container">
    <header>
      <h1>Muhammad Haseeb</h1>
      <p class="links">
        <a href="mailto:haseeb099m@gmail.com">Email</a> |
        <a href="https://github.com/ha405">GitHub</a> |
        <a href="https://linkedin.com/in/muhammad-haseeb">LinkedIn</a>
      </p>
    </header>

    <section>
      <h2>Research Interests</h2>
      <ul>
        <li>Efficient ML: pruning and quantization for compute- and memory-efficient models.</li>
        <li>Domain Generalization via sparse subnetworks preserving invariant representations.</li>
        <li>Mechanistic interpretability of representational collapse in federated learning.</li>
      </ul>
    </section>

    <section>
      <h2>Education</h2>
      <p><strong>Lahore University of Management Sciences (LUMS)</strong><br/>
      B.S. Computer Science (Sep 2022 – May 2026)</p>
      <p class="muted">
        Coursework: Machine Learning, Deep Learning, Computer Vision, AI on Edge Devices,
        Advanced Topics in ML, LLM Systems, Linear Algebra, Probability.
      </p>
    </section>

    <section>
      <h2>Publications</h2>
      <p>
        <strong>BaCP: Backbone Contrastive Pruning for Preserving Representations in Extremely Sparse Neural Networks</strong><br/>
        Mohammad Haroon Khawaja, Muhammad Haseeb, Mohammad Fatim Shoaib, Muhammad Tahir.<br/>
        Submitted to AAAI 2025.
      </p>
    </section>

    <section>
      <h2>Research Experience</h2>

      <p><strong>Research Assistant</strong> — CITY, LUMS (Jan 2025 – Present)<br/>
      Advisors: Dr. Muhammad Tahir, Dr. Zubair Khalid</p>
      <ul>
        <li>Developed Backbone Contrastive Pruning to prevent representational collapse at extreme sparsity.</li>
        <li>Designed multi-objective losses aligning sparse embeddings with dense and historical references.</li>
        <li>Matched dense baselines at up to 99% sparsity across CNNs, ViTs, and LMs.</li>
        <li>Worked on pruning-based domain generalization to remove domain-specific noise.</li>
        <li>Quantization of diffusion models via timestep-consistent learning objectives.</li>
      </ul>

      <p><strong>Research Assistant</strong> — CV & Graphics Lab, LUMS (Jan 2025 – Aug 2025)</p>
      <ul>
        <li>KLAWQ: KL-aware GPTQ with distillation and supervised fine-tuning.</li>
        <li>30% perplexity reduction over GPTQ at equal bit-widths.</li>
        <li>SOFI-UGCL: Transformer-based single-image camera calibration.</li>
      </ul>

      <p><strong>Research Intern</strong> — UIUC (May 2025 – Aug 2025)</p>
      <ul>
        <li>LLM heuristics for automated #ifdef insertion in C codebases.</li>
        <li>Software debloating and dependency analysis.</li>
        <li>VS Code extension for C-to-Rust translation.</li>
      </ul>
    </section>

    <section>
      <h2>Industry Experience</h2>
      <p><strong>Machine Learning Engineer (Contract)</strong> — Innova Tech (Jul 2025 – Oct 2025)</p>
      <ul>
        <li>Automated data annotation pipelines for object detection.</li>
        <li>Improved validation accuracy by ~4%.</li>
        <li>ONNX and TensorRT quantization achieving ~40% memory reduction.</li>
      </ul>
    </section>

    <section>
      <h2>Teaching</h2>
      <p><strong>Teaching Assistant</strong> — CS436: Computer Vision, LUMS (Sep 2025 – Dec 2025)</p>
      <ul>
        <li>Designed transfer learning and real-time C++/OpenCV assignments.</li>
        <li>Supervised 40 groups on an SfM-based virtual tour project.</li>
      </ul>
    </section>

    <section>
      <h2>Skills & Open Source</h2>
      <p>
        <strong>Languages:</strong> Python, C, C++, Rust, SQL, TypeScript<br/>
        <strong>ML:</strong> PyTorch, Transformers, ONNX, TensorRT, diffusers, adapters
      </p>
      <ul>
        <li>pytorch-image-models: added F1, precision, recall (single + distributed).</li>
        <li>adapters: PEFT support for Group Query Attention models.</li>
      </ul>
    </section>

    <footer>
      <p class="muted">Last updated: 2026</p>
    </footer>
  </div>
</body>
</html>
